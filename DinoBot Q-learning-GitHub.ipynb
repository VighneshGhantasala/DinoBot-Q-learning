{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Author: Vighnesh Ghantasala \n",
    "Github: https://github.com/VighneshGhantasala/\n",
    "'''\n",
    "\n",
    "import pyautogui as pg\n",
    "from PIL import ImageGrab, ImageOps\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "board_val = 0\n",
    "retry = 0\n",
    "LIFE = 0\n",
    "R_VAL = 1455 #normalized value sum of retry button pixels\n",
    "reward = 1\n",
    "states = [0]\n",
    "\n",
    "#Q-matrix\n",
    "old_q = np.zeros((20,3)) \n",
    "q = np.zeros((20,3))\n",
    "for i in range(q.shape[0]):\n",
    "    q[i,] = [0 ,1 ,1.5]\n",
    "    np.random.shuffle(q[i,])\n",
    "    old_q[i,] = q[i,]\n",
    "\n",
    "\n",
    "class Cordinates():\n",
    "    #You may need to  tweak these according your screen resolution\n",
    "    replay = (329,270,360,301) #replay button coordinates\n",
    "    replayBtn = (340,300) #approx center coordinates for replay button\n",
    "    dino = (105,313) #Dino coordinates Standing(86,290) sitting(105,313)\n",
    "    box = (93,290,159,330) #A rect in-front of our Agent \n",
    "def restart():\n",
    "    pg.click(Cordinates.replayBtn)\n",
    "\n",
    "def give_reward():\n",
    "    global reward\n",
    "    global R_VAL\n",
    "    c = Cordinates()\n",
    "    replay = ImageGrab.grab(c.replay) #get replay button position\n",
    "    replay = np.array(replay)\n",
    "    if int(replay.sum()/255) == R_VAL: #if replay button is seen then a life has beeen consumed\n",
    "        reward = 0 #reward 0 when dead\n",
    "    else:\n",
    "        reward = 1\n",
    "def do_none():\n",
    "    pg.keyDown(\"left\")\n",
    "    time.sleep(0.1)\n",
    "    print(\"Do nothing\")\n",
    "    pg.keyUp(\"left\")\n",
    "    give_reward()\n",
    "def jump():\n",
    "    pg.keyDown(\"space\")\n",
    "    time.sleep(0.1)\n",
    "    print(\"Jump\")\n",
    "    pg.keyUp(\"space\")\n",
    "    give_reward()\n",
    "\n",
    "\n",
    "def duck(): #crouch\n",
    "    \n",
    "    pg.keyDown(\"down\")\n",
    "    time.sleep(0.1)\n",
    "    print(\"duck\")\n",
    "    pg.keyUp(\"down\")\n",
    "    give_reward()\n",
    "\n",
    "def imgGrab():\n",
    "    global board_val\n",
    "    global retry\n",
    "    global reward\n",
    "    global R_VAL\n",
    "    c = Cordinates()\n",
    "    replay = ImageGrab.grab(c.replay) #get replay button position\n",
    "    replay = np.array(replay)\n",
    "    if int(replay.sum()/255) == R_VAL: #if replay button is seen then a life has beeen consumed\n",
    "        print(\"Life consumed\")\n",
    "        retry += 1\n",
    "\n",
    "    #print(reward)\n",
    "    img = ImageGrab.grab(c.box)\n",
    "    gray = ImageOps.grayscale(img)\n",
    "    a = np.array(gray.getcolors())\n",
    "    return a.sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score of run: 0\n",
      "Life: 0\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 3227 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "1\n",
      "action for 2978 is 1\n",
      "Jump\n",
      "0\n",
      "Life consumed\n"
     ]
    }
   ],
   "source": [
    "gamma = 0.8 #Discount factor\n",
    "score = 0 # Initial score value\n",
    "states = np.array(states)\n",
    "LIFE = 20 #no.of lifes for our Agent(Dino)\n",
    "\n",
    "def choose_action(state):\n",
    "    q_row_index = np.where(state == states)[0][0] #Get the row with the state\n",
    "    action = np.argmax(q[q_row_index,])\n",
    "    return action\n",
    "\n",
    "def update_q(current_state,action,reward):\n",
    "    '''\n",
    "    Q-Learning algorithm: \n",
    "    Q[current_state,action] = rewards[current_state,action] + gamma * max[Q[current_state,action]]    \n",
    "    \n",
    "    '''\n",
    "    \n",
    "    global gamma\n",
    "    global alpha\n",
    "    state_index = np.where(current_state == states)[0][0]\n",
    "    max_val = np.max(q[state_index,]) #This is the action we took\n",
    "    q[state_index,action] = reward + gamma * max_val # Algorithm\n",
    "\n",
    "def run():\n",
    "    global states\n",
    "    global score\n",
    "    global q\n",
    "    global reward\n",
    "    while True:\n",
    "        s = imgGrab()\n",
    "        #add new states to the states table\n",
    "        if(len(np.where(states == s)[0]) < 1):\n",
    "            states = np.append(states,s)\n",
    "\n",
    "        #print(reward)\n",
    "\n",
    "#         print(s)\n",
    "        if retry == 1:\n",
    "            #print(\"Game Over\")\n",
    "            break\n",
    "        if s != 2895 and s!=2640:\n",
    "            try:\n",
    "                act = choose_action(s)\n",
    "                print(\"action for {} is {}\".format(s,act))\n",
    "            except Exception as e:\n",
    "                pass\n",
    "            score += 1\n",
    "            #print(s)\n",
    "\n",
    "            #Perform action performed based on Q-table\n",
    "            #actions = {0:do nothing ,1:jump ,2:duck}\n",
    "            if act == 0:\n",
    "                do_none()\n",
    "                print(reward)\n",
    "                update_q(s,act,reward)\n",
    "            elif act == 1:\n",
    "                jump()\n",
    "                print(reward)\n",
    "                update_q(s,act,reward)\n",
    "            elif act == 2:\n",
    "                duck()\n",
    "#                 print(reward)\n",
    "                print(reward)\n",
    "                update_q(s,act,reward)\n",
    "            time.sleep(0.1)\n",
    "            \n",
    "        if score == 50:\n",
    "            print(\"Score Reached\")\n",
    "            break\n",
    "\n",
    "for i in range(LIFE):\n",
    "    if score == 50:\n",
    "        break\n",
    "    else:\n",
    "        print(\"Score of run:\",score)\n",
    "        score = 0\n",
    "        print(\"Life:\",i)\n",
    "        retry = 0\n",
    "        restart()\n",
    "        run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len & num states: 5 [   0 2895 2978 3227 3144]\n",
      "Q-matrix:\n",
      " [[0.         1.5        1.        ]\n",
      " [1.         0.         1.5       ]\n",
      " [1.         3.99876205 0.        ]\n",
      " [1.         4.96472933 0.        ]\n",
      " [0.         2.44       0.96      ]]\n",
      "\n",
      "\n",
      " initial Q-matrix\n",
      " [[0.  1.5 1. ]\n",
      " [1.  0.  1.5]\n",
      " [1.  1.5 0. ]\n",
      " [1.  1.5 0. ]\n",
      " [0.  1.  1.5]]\n"
     ]
    }
   ],
   "source": [
    "#Random Testing area \n",
    "\n",
    "\n",
    "def stats(): #prints stats like Q-matrix and states\n",
    "    print(\"len & num states:\",len(states),states)\n",
    "\n",
    "    print(\"Q-matrix:\\n\",q[:len(states)])\n",
    "\n",
    "stats()\n",
    "print(\"\\n\\n initial Q-matrix\\n\",old_q[:len(states)] )\n",
    "\n",
    "# In-case u want to save ur Q-matrix\n",
    "np.save(\"Dino_Q_matrix.npy\",q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1455\n",
      " \n"
     ]
    }
   ],
   "source": [
    "#Run this cell to obtain R_VAL (Just a helper cell)\n",
    "import pyautogui as pg\n",
    "from PIL import ImageGrab, ImageOps\n",
    "import time\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "\n",
    "c = Cordinates()\n",
    "#box = (c.dino[0]+70,290,c.dino[0]+120,c.dino[1]+5)\n",
    "img = ImageGrab.grab(c.replay)\n",
    "img = np.array(img)\n",
    "board_val = int(img.sum()/255)\n",
    "print(board_val)\n",
    "cv2.imshow(\"img\",np.array(img))\n",
    "\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "'''\n",
    "A sample Q-matrix\n",
    "\n",
    "len & states: 5 [   0 2895 2978 3227 3144]\n",
    "Q-matrix:\n",
    " [[0.         1.5        1.        ]\n",
    " [1.         0.         1.5       ]\n",
    " [1.         3.99876205 0.        ]\n",
    " [1.         4.96472933 0.        ]\n",
    " [0.         2.44       0.96      ]]\n",
    "\n",
    "initial Q-matrix: \n",
    " [[0.  1.5 1. ]\n",
    " [1.  0.  1.5]\n",
    " [1.  1.5 0. ]\n",
    " [1.  1.5 0. ]\n",
    " [0.  1.  1.5]]\n",
    "\n",
    "'''\n",
    "print(\" \")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
